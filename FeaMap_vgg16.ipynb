{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "from misc_functions import preprocess_image, recreate_image, save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNLayerVisualization():\n",
    "    \"\"\"\n",
    "        Produces an image that minimizes the loss of a convolution\n",
    "        operation for a specific layer and filter\n",
    "    \"\"\"\n",
    "    def __init__(self, model, selected_layer):\n",
    "        self.model = model\n",
    "        self.model.eval()\n",
    "        self.selected_layer = selected_layer\n",
    "        \n",
    "        self.conv_output = 0\n",
    "        # Create the folder to export images if not exists\n",
    "        if not os.path.exists('generated'):\n",
    "            os.makedirs('generated')\n",
    "        # Generate a random image\n",
    "        random_image = np.uint8(np.random.uniform(150, 180, (224, 224, 3)))\n",
    "        # Process image and return variable\n",
    "        self.processed_image = preprocess_image(random_image, False)\n",
    "        \n",
    "    def hook_layer(self):\n",
    "        def hook_function(module, grad_in, grad_out):\n",
    "            # Gets the conv output of the selected filter (from selected layer)\n",
    "            self.conv_output = grad_out[0, self.selected_filter]\n",
    "        # Hook the selected layer\n",
    "        self.model[self.selected_layer].register_forward_hook(hook_function)\n",
    "    def calculate_mean_activation(self):        \n",
    "            def sortSecond(val): \n",
    "                return val[1]         \n",
    "            filters = [] #X axis of bar chart\n",
    "            activations = [] # mean of activation in each filters\n",
    "            sele_filters = [] #filters No. and mean activation \n",
    "            maxfilter = [] #selected filters of each layer\n",
    "            sel_filter = 10 # amount of choosen filters       \n",
    "            x = self.processed_image\n",
    "            for index, layer in enumerate(self.model):\n",
    "                x = layer(x)\n",
    "                if index == self.selected_layer:\n",
    "                    break\n",
    "            print(self.selected_layer,'-', x.shape)\n",
    "            for k in range(x.shape[1]):\n",
    "                mea_act = float(torch.mean(x[0, k]))\n",
    "                filters.append(k)\n",
    "                activations.append(mea_act)\n",
    "                sele_filters.append((k,mea_act))\n",
    "\n",
    "            sele_filters.sort(key = sortSecond, reverse = True)          \n",
    "            for f in range(sel_filter):\n",
    "                maxfilter.append(sele_filters[f][0])\n",
    "            print(self.selected_layer,'-',maxfilter)       \n",
    "            return maxfilter\n",
    "    def visualise_layer_with_hooks(self,selected_filter):\n",
    "        # Hook the selected layer\n",
    "        self.hook_layer()\n",
    "        self.selected_filter = selected_filter\n",
    "        # Define optimizer for the image\n",
    "        optimizer = Adam([self.processed_image], lr=0.1, weight_decay=1e-6)\n",
    "        for i in range(1, 31):\n",
    "            optimizer.zero_grad()\n",
    "            # Assign create image to a variable to move forward in the model\n",
    "            x = self.processed_image\n",
    "            for index, layer in enumerate(self.model):\n",
    "                # Forward pass layer by layer\n",
    "                # x is not used after this point because it is only needed to trigger\n",
    "                # the forward hook function\n",
    "                x = layer(x)\n",
    "                # Only need to forward until the selected layer is reached\n",
    "                if index == self.selected_layer:\n",
    "                    #print('layer:',layer)\n",
    "                    # (forward hook function triggered)\n",
    "                    break\n",
    "            # Loss function is the mean of the output of the selected layer/filter\n",
    "            # We try to minimize the mean of the output of that specific filter\n",
    "            loss = -torch.mean(self.conv_output)\n",
    "#             print('Iteration:', str(i), 'Loss:', \"{0:.2f}\".format(loss.data.numpy()))\n",
    "            # Backward\n",
    "            loss.backward()\n",
    "            # Update image\n",
    "            optimizer.step()\n",
    "            # Recreate image\n",
    "            self.created_image = recreate_image(self.processed_image)\n",
    "            # Save image\n",
    "            if i % 5 == 0:\n",
    "                im_path = 'generated/layer_vis_l' + str(self.selected_layer) + \\\n",
    "                    '_f' + str(self.selected_filter) + '_iter' + str(i) + '.jpg'\n",
    "                save_image(self.created_image, im_path)\n",
    "\n",
    "    def visualise_layer_without_hooks(self):\n",
    "        # Process image and return variable\n",
    "        # Generate a random image       \n",
    "        random_image = np.uint8(np.random.uniform(150, 180, (224, 224, 3)))\n",
    "        # Process image and return variable\n",
    "        processed_image = preprocess_image(random_image, False)\n",
    "        # Define optimizer for the image\n",
    "        optimizer = Adam([processed_image], lr=0.1, weight_decay=1e-6)\n",
    "        for i in range(1, 31):\n",
    "            optimizer.zero_grad()\n",
    "            # Assign create image to a variable to move forward in the model\n",
    "            x = processed_image\n",
    "            #print(x.shape)\n",
    "\n",
    "            for index, layer in enumerate(self.model):\n",
    "                # Forward pass layer by layer\n",
    "                layer = list(self.model)[index]\n",
    "                x = layer(x)\n",
    "                \n",
    "#                 print(index)\n",
    "#                 print(x.shape)\n",
    "                \n",
    "                if index == self.selected_layer:\n",
    "                    \n",
    "                    # Only need to forward until the selected layer is reached\n",
    "                    # Now, x is the output of the selected layer\n",
    "                    break\n",
    "            # Here, we get the specific filter from the output of the convolution operation\n",
    "            # x is a tensor of shape 1x512x28x28.(For layer 17)\n",
    "            # So there are 512 unique filter outputs\n",
    "            # Following line selects a filter from 512 filters so self.conv_output will become\n",
    "            # a tensor of shape 28x28\n",
    "            self.conv_output = x[0, self.selected_filter]\n",
    "#             print(self.conv_output.shape)\n",
    "            # Loss function is the mean of the output of the selected layer/filter\n",
    "            # We try to minimize the mean of the output of that specific filter\n",
    "            loss = -torch.mean(self.conv_output)\n",
    "#             print('Iteration:', str(i), 'Loss:', \"{0:.2f}\".format(loss.data.numpy()))\n",
    "            # Backward\n",
    "            loss.backward()\n",
    "            # Update image\n",
    "            optimizer.step()\n",
    "            # Recreate image\n",
    "            self.created_image = recreate_image(processed_image)\n",
    "            # Save image\n",
    "            if i % 6 == 0:\n",
    "                im_path = 'generated/VGG_layer_res_vis_l' + str(self.selected_layer) + \\\n",
    "                    '_f' + str(self.selected_filter) + '_iter' + str(i) + '.jpg'\n",
    "                save_image(self.created_image, im_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - torch.Size([1, 64, 224, 224])\n",
      "0 - [51, 34, 19, 58, 59, 24, 57, 23, 53, 2]\n",
      "1 - torch.Size([1, 64, 224, 224])\n",
      "1 - [51, 34, 19, 58, 59, 24, 57, 23, 53, 2]\n",
      "2 - torch.Size([1, 64, 224, 224])\n",
      "2 - [40, 21, 56, 48, 2, 34, 3, 41, 55, 58]\n"
     ]
    }
   ],
   "source": [
    "pretrained_model = models.vgg16(pretrained=True).features\n",
    "for cnn_layer in range(30):\n",
    "    layer_vis = CNNLayerVisualization(pretrained_model, cnn_layer)\n",
    "    filter_pos = layer_vis.calculate_mean_activation()\n",
    "    for f in filter_pos:\n",
    "    # Fully connected layer is not needed\n",
    "        layer_vis.visualise_layer_with_hooks(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
