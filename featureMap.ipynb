{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-c914f957acd0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torchvision import models\n",
    "\n",
    "from misc_functions import preprocess_image, recreate_image, save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNLayerVisualization():\n",
    "    \"\"\"\n",
    "        Produces an image that minimizes the loss of a convolution\n",
    "        operation for a specific layer and filter\n",
    "    \"\"\"\n",
    "    def __init__(self, model, selected_layer, selected_filter):\n",
    "        self.model = model\n",
    "        self.model.eval()\n",
    "        self.selected_layer = selected_layer\n",
    "        self.selected_filter = selected_filter\n",
    "        self.conv_output = 0\n",
    "        # Create the folder to export images if not exists\n",
    "        if not os.path.exists('generated'):\n",
    "            os.makedirs('generated')\n",
    "\n",
    "    def hook_layer(self):\n",
    "        def hook_function(module, grad_in, grad_out):\n",
    "            # Gets the conv output of the selected filter (from selected layer)\n",
    "            self.conv_output = grad_out[0, self.selected_filter]\n",
    "        # Hook the selected layer\n",
    "        self.model[self.selected_layer].register_forward_hook(hook_function)\n",
    "\n",
    "    def visualise_layer_with_hooks(self):\n",
    "        # Hook the selected layer\n",
    "        self.hook_layer()\n",
    "        # Generate a random image\n",
    "        random_image = np.uint8(np.random.uniform(150, 180, (224, 224, 3)))\n",
    "        # Process image and return variable\n",
    "        processed_image = preprocess_image(random_image, False)\n",
    "        # Define optimizer for the image\n",
    "        optimizer = Adam([processed_image], lr=0.1, weight_decay=1e-6)\n",
    "        for i in range(1, 31):\n",
    "            optimizer.zero_grad()\n",
    "            # Assign create image to a variable to move forward in the model\n",
    "            x = processed_image\n",
    "            for index, layer in enumerate(self.model):\n",
    "                # Forward pass layer by layer\n",
    "                # x is not used after this point because it is only needed to trigger\n",
    "                # the forward hook function\n",
    "                x = layer(x)\n",
    "                # Only need to forward until the selected layer is reached\n",
    "                if index == self.selected_layer:\n",
    "                    # (forward hook function triggered)\n",
    "                    break\n",
    "            # Loss function is the mean of the output of the selected layer/filter\n",
    "            # We try to minimize the mean of the output of that specific filter\n",
    "            loss = -torch.mean(self.conv_output)\n",
    "            print('Iteration:', str(i), 'Loss:', \"{0:.2f}\".format(loss.data.numpy()))\n",
    "            # Backward\n",
    "            loss.backward()\n",
    "            # Update image\n",
    "            optimizer.step()\n",
    "            # Recreate image\n",
    "            self.created_image = recreate_image(processed_image)\n",
    "            # Save image\n",
    "            if i % 5 == 0:\n",
    "                im_path = 'generated/layer_vis_l' + str(self.selected_layer) + \\\n",
    "                    '_f' + str(self.selected_filter) + '_iter' + str(i) + '.jpg'\n",
    "                save_image(self.created_image, im_path)\n",
    "\n",
    "    def visualise_layer_without_hooks(self):\n",
    "        # Process image and return variable\n",
    "        # Generate a random image       \n",
    "        random_image = np.uint8(np.random.uniform(150, 180, (224, 224, 3)))\n",
    "        # Process image and return variable\n",
    "        processed_image = preprocess_image(random_image, False)\n",
    "        # Define optimizer for the image\n",
    "        optimizer = Adam([processed_image], lr=0.1, weight_decay=1e-6)\n",
    "        for i in range(1, 31):\n",
    "            optimizer.zero_grad()\n",
    "            # Assign create image to a variable to move forward in the model\n",
    "            x = processed_image\n",
    "            for index, layer in enumerate(self.model.children()):\n",
    "#             for index, layer in enumerate(self.model):\n",
    "                # Forward pass layer by layer\n",
    "                x = layer(x)\n",
    "#                 print(index)\n",
    "#                 print(x.shape)\n",
    "                if index == self.selected_layer:\n",
    "                    # Only need to forward until the selected layer is reached\n",
    "                    # Now, x is the output of the selected layer\n",
    "                    break\n",
    "            # Here, we get the specific filter from the output of the convolution operation\n",
    "            # x is a tensor of shape 1x512x28x28.(For layer 17)\n",
    "            # So there are 512 unique filter outputs\n",
    "            # Following line selects a filter from 512 filters so self.conv_output will become\n",
    "            # a tensor of shape 28x28\n",
    "            self.conv_output = x[0, self.selected_filter]\n",
    "#             print(self.conv_output.shape)\n",
    "            # Loss function is the mean of the output of the selected layer/filter\n",
    "            # We try to minimize the mean of the output of that specific filter\n",
    "            loss = -torch.mean(self.conv_output)\n",
    "            print('Iteration:', str(i), 'Loss:', \"{0:.2f}\".format(loss.data.numpy()))\n",
    "            # Backward\n",
    "            loss.backward()\n",
    "            # Update image\n",
    "            optimizer.step()\n",
    "            # Recreate image\n",
    "            self.created_image = recreate_image(processed_image)\n",
    "            # Save image\n",
    "            if i % 5 == 0:\n",
    "                im_path = 'generated/layer_res_vis_l' + str(self.selected_layer) + \\\n",
    "                    '_f' + str(self.selected_filter) + '_iter' + str(i) + '.jpg'\n",
    "                save_image(self.created_image, im_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_layer = 5\n",
    "filter_pos = 1\n",
    "# Fully connected layer is not needed\n",
    "pretrained_model = models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_layer = 17\n",
    "filter_pos = 5\n",
    "# Fully connected layer is not needed\n",
    "pretrained_model = models.vgg16(pretrained=True).features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "torch.Size([1, 64, 112, 112])\n",
      "1\n",
      "torch.Size([1, 64, 112, 112])\n",
      "2\n",
      "torch.Size([1, 64, 112, 112])\n",
      "3\n",
      "torch.Size([1, 64, 56, 56])\n",
      "4\n",
      "torch.Size([1, 64, 56, 56])\n",
      "5\n",
      "torch.Size([1, 128, 28, 28])\n",
      "Iteration: 1 Loss: -0.19\n",
      "0\n",
      "torch.Size([1, 64, 112, 112])\n",
      "1\n",
      "torch.Size([1, 64, 112, 112])\n",
      "2\n",
      "torch.Size([1, 64, 112, 112])\n",
      "3\n",
      "torch.Size([1, 64, 56, 56])\n",
      "4\n",
      "torch.Size([1, 64, 56, 56])\n",
      "5\n",
      "torch.Size([1, 128, 28, 28])\n",
      "Iteration: 2 Loss: -0.57\n",
      "0\n",
      "torch.Size([1, 64, 112, 112])\n",
      "1\n",
      "torch.Size([1, 64, 112, 112])\n",
      "2\n",
      "torch.Size([1, 64, 112, 112])\n",
      "3\n",
      "torch.Size([1, 64, 56, 56])\n",
      "4\n",
      "torch.Size([1, 64, 56, 56])\n",
      "5\n",
      "torch.Size([1, 128, 28, 28])\n",
      "Iteration: 3 Loss: -1.10\n",
      "0\n",
      "torch.Size([1, 64, 112, 112])\n",
      "1\n",
      "torch.Size([1, 64, 112, 112])\n",
      "2\n",
      "torch.Size([1, 64, 112, 112])\n",
      "3\n",
      "torch.Size([1, 64, 56, 56])\n",
      "4\n",
      "torch.Size([1, 64, 56, 56])\n",
      "5\n",
      "torch.Size([1, 128, 28, 28])\n",
      "Iteration: 4 Loss: -1.39\n",
      "0\n",
      "torch.Size([1, 64, 112, 112])\n",
      "1\n",
      "torch.Size([1, 64, 112, 112])\n",
      "2\n",
      "torch.Size([1, 64, 112, 112])\n",
      "3\n",
      "torch.Size([1, 64, 56, 56])\n",
      "4\n",
      "torch.Size([1, 64, 56, 56])\n",
      "5\n",
      "torch.Size([1, 128, 28, 28])\n",
      "Iteration: 5 Loss: -1.59\n",
      "0\n",
      "torch.Size([1, 64, 112, 112])\n",
      "1\n",
      "torch.Size([1, 64, 112, 112])\n",
      "2\n",
      "torch.Size([1, 64, 112, 112])\n",
      "3\n",
      "torch.Size([1, 64, 56, 56])\n",
      "4\n",
      "torch.Size([1, 64, 56, 56])\n",
      "5\n",
      "torch.Size([1, 128, 28, 28])\n",
      "Iteration: 6 Loss: -1.77\n",
      "0\n",
      "torch.Size([1, 64, 112, 112])\n",
      "1\n",
      "torch.Size([1, 64, 112, 112])\n",
      "2\n",
      "torch.Size([1, 64, 112, 112])\n",
      "3\n",
      "torch.Size([1, 64, 56, 56])\n",
      "4\n",
      "torch.Size([1, 64, 56, 56])\n",
      "5\n",
      "torch.Size([1, 128, 28, 28])\n",
      "Iteration: 7 Loss: -1.91\n",
      "0\n",
      "torch.Size([1, 64, 112, 112])\n",
      "1\n",
      "torch.Size([1, 64, 112, 112])\n",
      "2\n",
      "torch.Size([1, 64, 112, 112])\n",
      "3\n",
      "torch.Size([1, 64, 56, 56])\n",
      "4\n",
      "torch.Size([1, 64, 56, 56])\n",
      "5\n",
      "torch.Size([1, 128, 28, 28])\n",
      "Iteration: 8 Loss: -2.04\n",
      "0\n",
      "torch.Size([1, 64, 112, 112])\n",
      "1\n",
      "torch.Size([1, 64, 112, 112])\n",
      "2\n",
      "torch.Size([1, 64, 112, 112])\n",
      "3\n",
      "torch.Size([1, 64, 56, 56])\n",
      "4\n",
      "torch.Size([1, 64, 56, 56])\n",
      "5\n",
      "torch.Size([1, 128, 28, 28])\n",
      "Iteration: 9 Loss: -2.15\n",
      "0\n",
      "torch.Size([1, 64, 112, 112])\n",
      "1\n",
      "torch.Size([1, 64, 112, 112])\n",
      "2\n",
      "torch.Size([1, 64, 112, 112])\n",
      "3\n",
      "torch.Size([1, 64, 56, 56])\n",
      "4\n",
      "torch.Size([1, 64, 56, 56])\n",
      "5\n",
      "torch.Size([1, 128, 28, 28])\n",
      "Iteration: 10 Loss: -2.25\n",
      "0\n",
      "torch.Size([1, 64, 112, 112])\n",
      "1\n",
      "torch.Size([1, 64, 112, 112])\n",
      "2\n",
      "torch.Size([1, 64, 112, 112])\n",
      "3\n",
      "torch.Size([1, 64, 56, 56])\n",
      "4\n",
      "torch.Size([1, 64, 56, 56])\n",
      "5\n",
      "torch.Size([1, 128, 28, 28])\n",
      "Iteration: 11 Loss: -2.35\n",
      "0\n",
      "torch.Size([1, 64, 112, 112])\n",
      "1\n",
      "torch.Size([1, 64, 112, 112])\n",
      "2\n",
      "torch.Size([1, 64, 112, 112])\n",
      "3\n",
      "torch.Size([1, 64, 56, 56])\n",
      "4\n",
      "torch.Size([1, 64, 56, 56])\n",
      "5\n",
      "torch.Size([1, 128, 28, 28])\n",
      "Iteration: 12 Loss: -2.43\n",
      "0\n",
      "torch.Size([1, 64, 112, 112])\n",
      "1\n",
      "torch.Size([1, 64, 112, 112])\n",
      "2\n",
      "torch.Size([1, 64, 112, 112])\n",
      "3\n",
      "torch.Size([1, 64, 56, 56])\n",
      "4\n",
      "torch.Size([1, 64, 56, 56])\n",
      "5\n",
      "torch.Size([1, 128, 28, 28])\n",
      "Iteration: 13 Loss: -2.52\n",
      "0\n",
      "torch.Size([1, 64, 112, 112])\n",
      "1\n",
      "torch.Size([1, 64, 112, 112])\n",
      "2\n",
      "torch.Size([1, 64, 112, 112])\n",
      "3\n",
      "torch.Size([1, 64, 56, 56])\n",
      "4\n",
      "torch.Size([1, 64, 56, 56])\n",
      "5\n",
      "torch.Size([1, 128, 28, 28])\n",
      "Iteration: 14 Loss: -2.59\n",
      "0\n",
      "torch.Size([1, 64, 112, 112])\n",
      "1\n",
      "torch.Size([1, 64, 112, 112])\n",
      "2\n",
      "torch.Size([1, 64, 112, 112])\n",
      "3\n",
      "torch.Size([1, 64, 56, 56])\n",
      "4\n",
      "torch.Size([1, 64, 56, 56])\n",
      "5\n",
      "torch.Size([1, 128, 28, 28])\n",
      "Iteration: 15 Loss: -2.67\n",
      "0\n",
      "torch.Size([1, 64, 112, 112])\n",
      "1\n",
      "torch.Size([1, 64, 112, 112])\n",
      "2\n",
      "torch.Size([1, 64, 112, 112])\n",
      "3\n",
      "torch.Size([1, 64, 56, 56])\n",
      "4\n",
      "torch.Size([1, 64, 56, 56])\n",
      "5\n",
      "torch.Size([1, 128, 28, 28])\n",
      "Iteration: 16 Loss: -2.74\n",
      "0\n",
      "torch.Size([1, 64, 112, 112])\n",
      "1\n",
      "torch.Size([1, 64, 112, 112])\n",
      "2\n",
      "torch.Size([1, 64, 112, 112])\n",
      "3\n",
      "torch.Size([1, 64, 56, 56])\n",
      "4\n",
      "torch.Size([1, 64, 56, 56])\n",
      "5\n",
      "torch.Size([1, 128, 28, 28])\n",
      "Iteration: 17 Loss: -2.80\n",
      "0\n",
      "torch.Size([1, 64, 112, 112])\n",
      "1\n",
      "torch.Size([1, 64, 112, 112])\n",
      "2\n",
      "torch.Size([1, 64, 112, 112])\n",
      "3\n",
      "torch.Size([1, 64, 56, 56])\n",
      "4\n",
      "torch.Size([1, 64, 56, 56])\n",
      "5\n",
      "torch.Size([1, 128, 28, 28])\n",
      "Iteration: 18 Loss: -2.86\n",
      "0\n",
      "torch.Size([1, 64, 112, 112])\n",
      "1\n",
      "torch.Size([1, 64, 112, 112])\n",
      "2\n",
      "torch.Size([1, 64, 112, 112])\n",
      "3\n",
      "torch.Size([1, 64, 56, 56])\n",
      "4\n",
      "torch.Size([1, 64, 56, 56])\n",
      "5\n",
      "torch.Size([1, 128, 28, 28])\n",
      "Iteration: 19 Loss: -2.92\n",
      "0\n",
      "torch.Size([1, 64, 112, 112])\n",
      "1\n",
      "torch.Size([1, 64, 112, 112])\n",
      "2\n",
      "torch.Size([1, 64, 112, 112])\n",
      "3\n",
      "torch.Size([1, 64, 56, 56])\n",
      "4\n",
      "torch.Size([1, 64, 56, 56])\n",
      "5\n",
      "torch.Size([1, 128, 28, 28])\n",
      "Iteration: 20 Loss: -2.98\n",
      "0\n",
      "torch.Size([1, 64, 112, 112])\n",
      "1\n",
      "torch.Size([1, 64, 112, 112])\n",
      "2\n",
      "torch.Size([1, 64, 112, 112])\n",
      "3\n",
      "torch.Size([1, 64, 56, 56])\n",
      "4\n",
      "torch.Size([1, 64, 56, 56])\n",
      "5\n",
      "torch.Size([1, 128, 28, 28])\n",
      "Iteration: 21 Loss: -3.04\n",
      "0\n",
      "torch.Size([1, 64, 112, 112])\n",
      "1\n",
      "torch.Size([1, 64, 112, 112])\n",
      "2\n",
      "torch.Size([1, 64, 112, 112])\n",
      "3\n",
      "torch.Size([1, 64, 56, 56])\n",
      "4\n",
      "torch.Size([1, 64, 56, 56])\n",
      "5\n",
      "torch.Size([1, 128, 28, 28])\n",
      "Iteration: 22 Loss: -3.10\n",
      "0\n",
      "torch.Size([1, 64, 112, 112])\n",
      "1\n",
      "torch.Size([1, 64, 112, 112])\n",
      "2\n",
      "torch.Size([1, 64, 112, 112])\n",
      "3\n",
      "torch.Size([1, 64, 56, 56])\n",
      "4\n",
      "torch.Size([1, 64, 56, 56])\n",
      "5\n",
      "torch.Size([1, 128, 28, 28])\n",
      "Iteration: 23 Loss: -3.15\n",
      "0\n",
      "torch.Size([1, 64, 112, 112])\n",
      "1\n",
      "torch.Size([1, 64, 112, 112])\n",
      "2\n",
      "torch.Size([1, 64, 112, 112])\n",
      "3\n",
      "torch.Size([1, 64, 56, 56])\n",
      "4\n",
      "torch.Size([1, 64, 56, 56])\n",
      "5\n",
      "torch.Size([1, 128, 28, 28])\n",
      "Iteration: 24 Loss: -3.20\n",
      "0\n",
      "torch.Size([1, 64, 112, 112])\n",
      "1\n",
      "torch.Size([1, 64, 112, 112])\n",
      "2\n",
      "torch.Size([1, 64, 112, 112])\n",
      "3\n",
      "torch.Size([1, 64, 56, 56])\n",
      "4\n",
      "torch.Size([1, 64, 56, 56])\n",
      "5\n",
      "torch.Size([1, 128, 28, 28])\n",
      "Iteration: 25 Loss: -3.25\n",
      "0\n",
      "torch.Size([1, 64, 112, 112])\n",
      "1\n",
      "torch.Size([1, 64, 112, 112])\n",
      "2\n",
      "torch.Size([1, 64, 112, 112])\n",
      "3\n",
      "torch.Size([1, 64, 56, 56])\n",
      "4\n",
      "torch.Size([1, 64, 56, 56])\n",
      "5\n",
      "torch.Size([1, 128, 28, 28])\n",
      "Iteration: 26 Loss: -3.30\n",
      "0\n",
      "torch.Size([1, 64, 112, 112])\n",
      "1\n",
      "torch.Size([1, 64, 112, 112])\n",
      "2\n",
      "torch.Size([1, 64, 112, 112])\n",
      "3\n",
      "torch.Size([1, 64, 56, 56])\n",
      "4\n",
      "torch.Size([1, 64, 56, 56])\n",
      "5\n",
      "torch.Size([1, 128, 28, 28])\n",
      "Iteration: 27 Loss: -3.35\n",
      "0\n",
      "torch.Size([1, 64, 112, 112])\n",
      "1\n",
      "torch.Size([1, 64, 112, 112])\n",
      "2\n",
      "torch.Size([1, 64, 112, 112])\n",
      "3\n",
      "torch.Size([1, 64, 56, 56])\n",
      "4\n",
      "torch.Size([1, 64, 56, 56])\n",
      "5\n",
      "torch.Size([1, 128, 28, 28])\n",
      "Iteration: 28 Loss: -3.40\n",
      "0\n",
      "torch.Size([1, 64, 112, 112])\n",
      "1\n",
      "torch.Size([1, 64, 112, 112])\n",
      "2\n",
      "torch.Size([1, 64, 112, 112])\n",
      "3\n",
      "torch.Size([1, 64, 56, 56])\n",
      "4\n",
      "torch.Size([1, 64, 56, 56])\n",
      "5\n",
      "torch.Size([1, 128, 28, 28])\n",
      "Iteration: 29 Loss: -3.44\n",
      "0\n",
      "torch.Size([1, 64, 112, 112])\n",
      "1\n",
      "torch.Size([1, 64, 112, 112])\n",
      "2\n",
      "torch.Size([1, 64, 112, 112])\n",
      "3\n",
      "torch.Size([1, 64, 56, 56])\n",
      "4\n",
      "torch.Size([1, 64, 56, 56])\n",
      "5\n",
      "torch.Size([1, 128, 28, 28])\n",
      "Iteration: 30 Loss: -3.49\n"
     ]
    }
   ],
   "source": [
    "layer_vis = CNNLayerVisualization(pretrained_model, cnn_layer, filter_pos)\n",
    "\n",
    "# Layer visualization with pytorch hooks\n",
    "# layer_vis.visualise_layer_with_hooks()\n",
    "layer_vis.visualise_layer_without_hooks()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
